{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"An open source collection of single-objective optimization algorithms for multi-dimensional functions. The purpose of this library is to give users access to a variety of versatile black-box optimization algorithms with extreme ease of use and interoperability. The parameters of each of the algorithms can be tuned by the users and there is a high level of parameter uniformity between algorithms. Benefits of using Optiseek include: support for float, integer, categorical, and boolean inputs for objective functions compatibility with black-box objective functions (requires no information on gradients or form of function) the algorithms are simple compared to alternatives (e.g. Bayesian optimization) with faster runtime on basic objective functions competitive convergence for computionally expensive objective functions in terms of number of function evaluations seamless integration into ML pipelines for hyper-parameter tuning access to a variety of stopping criteria, suitable for both computationally expensive and cheap objective functions carefully chosen default parameters for algorithms, with ability for user-defined fine tuning Installation pip install optiseek Usage optiseek provides access to numerous optimization algorithms that require minimal effort from the user. An example using the well-known particle swarm optimization algorithm can be as simple as this: from optiseek.variables import var_float from optiseek.metaheuristics import particle_swarm_optimizer from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = particle_swarm_optimizer(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=10) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.00217 best_position = {'x1': 0.9921537320723116, 'x2': 3.0265668104168326} n_iter = 10 This is a fairly basic example implementation without much thought put into parameter selection. Of course, the user is free to tune the parameters of the algorithm any way they would like. License optiseek was created by Alex Dundore. It is licensed under the terms of the MIT license. Credits and Dependencies optiseek is powered by numpy .","title":"Home"},{"location":"#installation","text":"pip install optiseek","title":"Installation"},{"location":"#usage","text":"optiseek provides access to numerous optimization algorithms that require minimal effort from the user. An example using the well-known particle swarm optimization algorithm can be as simple as this: from optiseek.variables import var_float from optiseek.metaheuristics import particle_swarm_optimizer from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = particle_swarm_optimizer(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=10) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.00217 best_position = {'x1': 0.9921537320723116, 'x2': 3.0265668104168326} n_iter = 10 This is a fairly basic example implementation without much thought put into parameter selection. Of course, the user is free to tune the parameters of the algorithm any way they would like.","title":"Usage"},{"location":"#license","text":"optiseek was created by Alex Dundore. It is licensed under the terms of the MIT license.","title":"License"},{"location":"#credits-and-dependencies","text":"optiseek is powered by numpy .","title":"Credits and Dependencies"},{"location":"ackley/","text":"Ackley Function This is a non-convex function with many local optima around a single global minimum of zero at [0, 0, ... , 0]. This function implementation can be scaled to any number of dimensions depending on the number of inputs passed. Form of the function is as follows: function optiseek.testfunctions. ackley ( *args ) Parameters Parameter Description *args : float Dynamic amount of x values for the function. The dimension of the function adjusts to how many arguments are entered. Example from optiseek.testfunctions import ackley y = ackley(0, 0) print(y) 0 References List of Test Functions on Wikipedia","title":"Ackley Function"},{"location":"ackley/#ackley-function","text":"This is a non-convex function with many local optima around a single global minimum of zero at [0, 0, ... , 0]. This function implementation can be scaled to any number of dimensions depending on the number of inputs passed. Form of the function is as follows: function optiseek.testfunctions. ackley ( *args )","title":"Ackley Function"},{"location":"ackley/#parameters","text":"Parameter Description *args : float Dynamic amount of x values for the function. The dimension of the function adjusts to how many arguments are entered.","title":"Parameters"},{"location":"ackley/#example","text":"from optiseek.testfunctions import ackley y = ackley(0, 0) print(y) 0","title":"Example"},{"location":"ackley/#references","text":"List of Test Functions on Wikipedia","title":"References"},{"location":"booth/","text":"Booth Function This is a simple 2D quadratic function with a minimum of zero at [1, 3]. Form of the function is as follows: function optiseek.testfunctions. booth ( x1, x2 ) Parameters Parameter Description x1 : float Input value for the first dimension. x2 : float Input value for the second dimension. Example from optiseek.testfunctions import booth y = booth(1, 3) print(y) 0 References List of Test Functions on Wikipedia","title":"Booth Function"},{"location":"booth/#booth-function","text":"This is a simple 2D quadratic function with a minimum of zero at [1, 3]. Form of the function is as follows: function optiseek.testfunctions. booth ( x1, x2 )","title":"Booth Function"},{"location":"booth/#parameters","text":"Parameter Description x1 : float Input value for the first dimension. x2 : float Input value for the second dimension.","title":"Parameters"},{"location":"booth/#example","text":"from optiseek.testfunctions import booth y = booth(1, 3) print(y) 0","title":"Example"},{"location":"booth/#references","text":"List of Test Functions on Wikipedia","title":"References"},{"location":"differential_evolution/","text":"Differential Evolution This class represents the differential evolution algorithm developed by Storn and Price. This is an evolutionary algorithm that utilizes vector-based genetic crossovers. It contains the typical components of a genetic algorithm (mutation, crossover, & selection) but has a special unique form of crossover that makes it widely applicable to a diverse set of problems. There are also very few parameters, making it simple to tune. class optiseek.metaheuristics. differential_evolution ( input_function=None, var_list=None, linspaced_initial_positions=True, results_filename=None, n_agents=None, weight=0.8, p_crossover=0.9 ) Parameters All parameters are also class attributes and may be modified after instantiation. Parameter Description input_function : function Function that the algorithm will use to search for an optimum. *args will be passed to the function within the solver. var_list : list of variables List of variables (see variable types) to define the search space. These correspond to the arguments of the objective function and must be in the exact same order. linspaced_initial_positions : bool If true, creates a linearly spaced set of points in each search dimension, and the initial positions of the population are set to mutually exclusive combinations of these points. This guarantees that there will be no empty spots in a single dimension. If false, random initial positions are chosen. results_filename : string If a file name is passed (ending in '.csv'), the results will be written to this file after each function evaluation. This can noticeably slow down solution iterations for quick objective functions. For greedy functions, it can be beneficial to do this in case the script is interrupted. n_agents : int Number of agents to use in the population. If set to None , the population size will be based on the heuristic 10 + 2 * sqrt(n_dims), where n_dims is the dimensionality of the search space. This is typically sufficient to explore the whole search space. weight : float Differential weight coefficient in [0, 2]. Higher values increase the impact of genetic crossover. p_crossover : float Probability in [0, 1] that a gene crossover will occur for each dimension. Attributes Attribute Description best_position : dict Dictionary containing the most optimal position found during the solution iterations, with variable names as keys and corresponding position values as values. best_value : float Most optimal function value found during the solution iterations. completed_iter : int Number of iterations completed during the solution process. results : pd.DataFrame DataFrame of results throughout the iterations. For each iteration, the function value and position for each member of the population are provided. Methods .optimize ( find_minimum, max_iter=None, max_function_evals=None, max_unchanged_iter=None, sol_threshold=None ) Executes the algorithm solution with the current parameters. Results will be stored to the class attributes. Either max_iter or max_function_evals must be specified in order to prevent an endless optimization loop. If any of the criteria are met during optimization, the process is terminated. Argument Description find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. max_iter : int Maximum number of iterations. The algorithm will terminate after completing this many iterations. None indicates that the algorithm will not consider this. max_function_evals : int Maximum number of function evaluations. Must be greater than the size of the population (i.e. complete at least one iteration). The algorithm will terminate after completing this many function evaluations. This is a preferable metric for greedy algorithms. None indicates that the algorithm will not consider this. max_unchanged_iter : int If the solution does not improve after this many iterations, the optimization terminates. None indicates that the algorithm will not consider this. sol_threshold : float If a solution is found better than this threshold, the iterations stop. None indicates that the algorithm will not consider this. Example from optiseek.variables import var_float from optiseek.metaheuristics import differential_evolution from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = differential_evolution(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=10, sol_threshold=0.05) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.07129 best_position = {'x1': 0.9199999999999992, 'x2': 3.1733333333333325} n_iter = 10 References Differential Evolution on Wikipedia","title":"Differential Evolution"},{"location":"differential_evolution/#differential-evolution","text":"This class represents the differential evolution algorithm developed by Storn and Price. This is an evolutionary algorithm that utilizes vector-based genetic crossovers. It contains the typical components of a genetic algorithm (mutation, crossover, & selection) but has a special unique form of crossover that makes it widely applicable to a diverse set of problems. There are also very few parameters, making it simple to tune. class optiseek.metaheuristics. differential_evolution ( input_function=None, var_list=None, linspaced_initial_positions=True, results_filename=None, n_agents=None, weight=0.8, p_crossover=0.9 )","title":"Differential Evolution"},{"location":"differential_evolution/#parameters","text":"All parameters are also class attributes and may be modified after instantiation. Parameter Description input_function : function Function that the algorithm will use to search for an optimum. *args will be passed to the function within the solver. var_list : list of variables List of variables (see variable types) to define the search space. These correspond to the arguments of the objective function and must be in the exact same order. linspaced_initial_positions : bool If true, creates a linearly spaced set of points in each search dimension, and the initial positions of the population are set to mutually exclusive combinations of these points. This guarantees that there will be no empty spots in a single dimension. If false, random initial positions are chosen. results_filename : string If a file name is passed (ending in '.csv'), the results will be written to this file after each function evaluation. This can noticeably slow down solution iterations for quick objective functions. For greedy functions, it can be beneficial to do this in case the script is interrupted. n_agents : int Number of agents to use in the population. If set to None , the population size will be based on the heuristic 10 + 2 * sqrt(n_dims), where n_dims is the dimensionality of the search space. This is typically sufficient to explore the whole search space. weight : float Differential weight coefficient in [0, 2]. Higher values increase the impact of genetic crossover. p_crossover : float Probability in [0, 1] that a gene crossover will occur for each dimension.","title":"Parameters"},{"location":"differential_evolution/#attributes","text":"Attribute Description best_position : dict Dictionary containing the most optimal position found during the solution iterations, with variable names as keys and corresponding position values as values. best_value : float Most optimal function value found during the solution iterations. completed_iter : int Number of iterations completed during the solution process. results : pd.DataFrame DataFrame of results throughout the iterations. For each iteration, the function value and position for each member of the population are provided.","title":"Attributes"},{"location":"differential_evolution/#methods","text":".optimize ( find_minimum, max_iter=None, max_function_evals=None, max_unchanged_iter=None, sol_threshold=None ) Executes the algorithm solution with the current parameters. Results will be stored to the class attributes. Either max_iter or max_function_evals must be specified in order to prevent an endless optimization loop. If any of the criteria are met during optimization, the process is terminated. Argument Description find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. max_iter : int Maximum number of iterations. The algorithm will terminate after completing this many iterations. None indicates that the algorithm will not consider this. max_function_evals : int Maximum number of function evaluations. Must be greater than the size of the population (i.e. complete at least one iteration). The algorithm will terminate after completing this many function evaluations. This is a preferable metric for greedy algorithms. None indicates that the algorithm will not consider this. max_unchanged_iter : int If the solution does not improve after this many iterations, the optimization terminates. None indicates that the algorithm will not consider this. sol_threshold : float If a solution is found better than this threshold, the iterations stop. None indicates that the algorithm will not consider this.","title":"Methods"},{"location":"differential_evolution/#example","text":"from optiseek.variables import var_float from optiseek.metaheuristics import differential_evolution from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = differential_evolution(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=10, sol_threshold=0.05) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.07129 best_position = {'x1': 0.9199999999999992, 'x2': 3.1733333333333325} n_iter = 10","title":"Example"},{"location":"differential_evolution/#references","text":"Differential Evolution on Wikipedia","title":"References"},{"location":"examples/","text":"Quick Start Guide The purpose of this package is to give users access to a class of optimization algorithms called metaheuristics with an easy-to-use and versatile API. The word \"metaheuristics\" comes from \"meta\", meaning beyond , and \"heuristic\", meaning to find . Most algorithms of this type are based on a naturally occurring process that has the emergent property of tending towards an optimum. For example, there are metaheuristics influenced by natural selection of genes (evolutionary algorithms), swarm behavior of insects (particle swarm optimization), and annealing in metals at the atomic level (simulated annealing), to name a few. Although they are not guaranteed to find the global optimum, these algorithms perform exceptionally well in both exploration and exploitation of large, high-dimensional search spaces. They also have the benefit of not needing any knowledge of the form of the function (i.e. black box functions). The algorithms in optiseek are applicable to a wide array of problems, including: high dimensionality black-box objective functions computationally expensive objective functions (i.e. the function evaluations are costly or slow), like hyperparameter tuning in Machine Learning non-expensive objective functions, as the optimizers have little computational overhead problems with a considerable amount of constraints on the search space objective functions with variables of mixed types (continuous, integer, categorical, boolean) To demonstrate the versatility of the algorithms in this package, some examples are provided. Example: Continous Variables First, let's optimize the 2-Dimensional Ackley function. This is a problem with 2 continuous variables as input, and a minimum of zero at [0, 0]. The ackley function is included with optiseek . from optiseek.variables import var_float from optiseek.metaheuristics import particle_swarm_optimizer from optiseek.testfunctions import ackley # define variable list and search domain var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # instantiate an optimization algorithm with the function and search domain alg = particle_swarm_optimizer(ackley, var_list) # set stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=100) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') best_value = 0.00000 best_position = {'x1': 2.8710730581797484e-17, 'x2': -3.254202051602899e-16} Example: Mixed-Type Variables Because optiseek 's algorithms also support mixed-type variables for the objective function, we will create a custom version of the ackley for demonstration purposes. We will modify the standard function output with an integer, categorical, and boolean variable. The way the modified function is written, it will maintain a minimum of zero at [0, 0]. from optiseek.variables import * from optiseek.metaheuristics import particle_swarm_optimizer from optiseek.testfunctions import ackley # create modified version of the ackley function def ackley_mixed(x1, x2, x_int, x_cat, x_bool): output = ackley(x1, x2) output += x_int * 2 if x_cat == 'A': output = output elif x_cat == 'B': output = 3 * output else: output = 2 * output output += int(x_bool) * 2 return output # define variable list and search domain var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]), var_int('x_int', [0, 5]), var_categorical('x_cat', ['A', 'B', 'C']), var_bool('x_bool') ] # instantiate an optimization algorithm with the function and search domain alg = particle_swarm_optimizer(ackley_mixed, var_list) # set stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=100) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') best_value = 0.00000 best_position = {'x1': 2.9828990486468627e-16, 'x2': -1.8893781942141117e-16, 'x_int': 0, 'x_cat': 'A', 'x_bool': False} Example: Hyperparameter Tuning in ML Algorithms For this example, we will use the scikit-learn and lightgbm packages for our ML tools, the California Housing dataset, and MRSE as the error metric. Note that the example uses max_function_evals for the stopping criterion, because performing cross-validation makes for a greedy objective function. In this case, we want to set a limit on the maximum number of allowed function evaluations. Also, we pass a file name to the results_filename optimization argument to preserve our results in the case that we need to terminate the algorithm prematurely. The steps to tuning hyperparameters for an ML algorithm with optiseek are straighforward: Prepare the training data Create a function that performs cross-validation with the hyperparameters are arguments and error metric as output Define the search space Pass this to an algorithm in optiseek and optimize # imports from optiseek.variables import * from optiseek.metaheuristics import particle_swarm_optimizer from sklearn.datasets import fetch_california_housing from sklearn.model_selection import cross_validate from lightgbm import LGBMRegressor # import and prepare the data california_housing = fetch_california_housing(as_frame=True) X = california_housing.data y = california_housing.target # set up cross-validation of the model as the objective function def objective_function(learning_rate, num_leaves, max_depth, min_child_weight, min_child_samples, subsample, colsample_bytree, reg_alpha): # assign the parameters params = { 'n_estimators': 300, 'learning_rate': learning_rate, 'num_leaves': num_leaves, 'max_depth': max_depth, 'min_child_weight': min_child_weight, 'min_child_samples': min_child_samples, 'subsample': subsample, 'colsample_bytree': colsample_bytree, 'reg_alpha': reg_alpha, 'verbose': -1 } # create the model model = LGBMRegressor(**params) # cross validate and return average validation MRSE cv_results = cross_validate(model, X, y, scoring='neg_root_mean_squared_error', cv=5) cv_score = -np.mean(cv_results['test_score']) return cv_score # define the search space var_list = [ var_float('learning_rate', [0.001, 0.3]), var_int('num_leaves', [20, 3000]), var_int('max_depth', [3, 12]), var_float('min_child_weight', [0.0005, 0.1]), var_int('min_child_samples', [5, 50]), var_float('subsample', [0.5, 1]), var_float('colsample_bytree', [0.5, 1]), var_float('reg_alpha', [0.001, 0.1]) ] # instantiate an optimization algorithm with the function and search domain alg = particle_swarm_optimizer(objective_function, var_list, results_filename='cv_results.csv') # set stopping criteria and optimize alg.optimize(find_minimum=True, max_function_evals=300) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') best_value = 0.60881 best_position = {'learning_rate': 0.24843279626513076, 'num_leaves': 3000, 'max_depth': 3, 'min_child_weight': 0.06303795879741575, 'min_child_samples': 27, 'subsample': 0.5, 'colsample_bytree': 0.9620615099733333, 'reg_alpha': 0.022922559999999998} Example: Constrained Objective Functions Refer to the penalty_constraints page for multiple examples on applying constraints to objective functions.","title":"Quick Start Examples"},{"location":"examples/#quick-start-guide","text":"The purpose of this package is to give users access to a class of optimization algorithms called metaheuristics with an easy-to-use and versatile API. The word \"metaheuristics\" comes from \"meta\", meaning beyond , and \"heuristic\", meaning to find . Most algorithms of this type are based on a naturally occurring process that has the emergent property of tending towards an optimum. For example, there are metaheuristics influenced by natural selection of genes (evolutionary algorithms), swarm behavior of insects (particle swarm optimization), and annealing in metals at the atomic level (simulated annealing), to name a few. Although they are not guaranteed to find the global optimum, these algorithms perform exceptionally well in both exploration and exploitation of large, high-dimensional search spaces. They also have the benefit of not needing any knowledge of the form of the function (i.e. black box functions). The algorithms in optiseek are applicable to a wide array of problems, including: high dimensionality black-box objective functions computationally expensive objective functions (i.e. the function evaluations are costly or slow), like hyperparameter tuning in Machine Learning non-expensive objective functions, as the optimizers have little computational overhead problems with a considerable amount of constraints on the search space objective functions with variables of mixed types (continuous, integer, categorical, boolean) To demonstrate the versatility of the algorithms in this package, some examples are provided.","title":"Quick Start Guide"},{"location":"examples/#example-continous-variables","text":"First, let's optimize the 2-Dimensional Ackley function. This is a problem with 2 continuous variables as input, and a minimum of zero at [0, 0]. The ackley function is included with optiseek . from optiseek.variables import var_float from optiseek.metaheuristics import particle_swarm_optimizer from optiseek.testfunctions import ackley # define variable list and search domain var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # instantiate an optimization algorithm with the function and search domain alg = particle_swarm_optimizer(ackley, var_list) # set stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=100) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') best_value = 0.00000 best_position = {'x1': 2.8710730581797484e-17, 'x2': -3.254202051602899e-16}","title":"Example: Continous Variables"},{"location":"examples/#example-mixed-type-variables","text":"Because optiseek 's algorithms also support mixed-type variables for the objective function, we will create a custom version of the ackley for demonstration purposes. We will modify the standard function output with an integer, categorical, and boolean variable. The way the modified function is written, it will maintain a minimum of zero at [0, 0]. from optiseek.variables import * from optiseek.metaheuristics import particle_swarm_optimizer from optiseek.testfunctions import ackley # create modified version of the ackley function def ackley_mixed(x1, x2, x_int, x_cat, x_bool): output = ackley(x1, x2) output += x_int * 2 if x_cat == 'A': output = output elif x_cat == 'B': output = 3 * output else: output = 2 * output output += int(x_bool) * 2 return output # define variable list and search domain var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]), var_int('x_int', [0, 5]), var_categorical('x_cat', ['A', 'B', 'C']), var_bool('x_bool') ] # instantiate an optimization algorithm with the function and search domain alg = particle_swarm_optimizer(ackley_mixed, var_list) # set stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=100) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') best_value = 0.00000 best_position = {'x1': 2.9828990486468627e-16, 'x2': -1.8893781942141117e-16, 'x_int': 0, 'x_cat': 'A', 'x_bool': False}","title":"Example: Mixed-Type Variables"},{"location":"examples/#example-hyperparameter-tuning-in-ml-algorithms","text":"For this example, we will use the scikit-learn and lightgbm packages for our ML tools, the California Housing dataset, and MRSE as the error metric. Note that the example uses max_function_evals for the stopping criterion, because performing cross-validation makes for a greedy objective function. In this case, we want to set a limit on the maximum number of allowed function evaluations. Also, we pass a file name to the results_filename optimization argument to preserve our results in the case that we need to terminate the algorithm prematurely. The steps to tuning hyperparameters for an ML algorithm with optiseek are straighforward: Prepare the training data Create a function that performs cross-validation with the hyperparameters are arguments and error metric as output Define the search space Pass this to an algorithm in optiseek and optimize # imports from optiseek.variables import * from optiseek.metaheuristics import particle_swarm_optimizer from sklearn.datasets import fetch_california_housing from sklearn.model_selection import cross_validate from lightgbm import LGBMRegressor # import and prepare the data california_housing = fetch_california_housing(as_frame=True) X = california_housing.data y = california_housing.target # set up cross-validation of the model as the objective function def objective_function(learning_rate, num_leaves, max_depth, min_child_weight, min_child_samples, subsample, colsample_bytree, reg_alpha): # assign the parameters params = { 'n_estimators': 300, 'learning_rate': learning_rate, 'num_leaves': num_leaves, 'max_depth': max_depth, 'min_child_weight': min_child_weight, 'min_child_samples': min_child_samples, 'subsample': subsample, 'colsample_bytree': colsample_bytree, 'reg_alpha': reg_alpha, 'verbose': -1 } # create the model model = LGBMRegressor(**params) # cross validate and return average validation MRSE cv_results = cross_validate(model, X, y, scoring='neg_root_mean_squared_error', cv=5) cv_score = -np.mean(cv_results['test_score']) return cv_score # define the search space var_list = [ var_float('learning_rate', [0.001, 0.3]), var_int('num_leaves', [20, 3000]), var_int('max_depth', [3, 12]), var_float('min_child_weight', [0.0005, 0.1]), var_int('min_child_samples', [5, 50]), var_float('subsample', [0.5, 1]), var_float('colsample_bytree', [0.5, 1]), var_float('reg_alpha', [0.001, 0.1]) ] # instantiate an optimization algorithm with the function and search domain alg = particle_swarm_optimizer(objective_function, var_list, results_filename='cv_results.csv') # set stopping criteria and optimize alg.optimize(find_minimum=True, max_function_evals=300) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') best_value = 0.60881 best_position = {'learning_rate': 0.24843279626513076, 'num_leaves': 3000, 'max_depth': 3, 'min_child_weight': 0.06303795879741575, 'min_child_samples': 27, 'subsample': 0.5, 'colsample_bytree': 0.9620615099733333, 'reg_alpha': 0.022922559999999998}","title":"Example: Hyperparameter Tuning in ML Algorithms"},{"location":"examples/#example-constrained-objective-functions","text":"Refer to the penalty_constraints page for multiple examples on applying constraints to objective functions.","title":"Example: Constrained Objective Functions"},{"location":"firefly_algorithm/","text":"Firefly Algorithm This class represents the firefly algorithm developed by Xin-She Yang. This algorithm is based on the flashing patterns and swarm behavior of fireflies. Fireflies are attracted to others based on their proximity in the search space and the brightness (function values) of others. Their movements also have a stochastic component. class optiseek.metaheuristics. firefly_algorithm ( input_function=None, var_list=None, linspaced_initial_positions=True, results_filename=None, n_fireflies=None, beta=1.0, alpha=0.05, gamma=0.5 ) Parameters All parameters are also class attributes and may be modified after instantiation. Parameter Description input_function : function Function that the algorithm will use to search for an optimum. *args will be passed to the function within the solver. var_list : list of variables List of variables (see variable types) to define the search space. These correspond to the arguments of the objective function and must be in the exact same order. linspaced_initial_positions : bool If true, creates a linearly spaced set of points in each search dimension, and the initial positions of the population are set to mutually exclusive combinations of these points. This guarantees that there will be no empty spots in a single dimension. If false, random initial positions are chosen. results_filename : string If a file name is passed (ending in '.csv'), the results will be written to this file after each function evaluation. This can noticeably slow down solution iterations for quick objective functions. For greedy functions, it can be beneficial to do this in case the script is interrupted. n_fireflies : int Number of fireflies to use in the swarm population. If set to None , the population size will be based on the heuristic 10 + 2 * sqrt(n_dims), where n_dims is the dimensionality of the search space. This is typically sufficient to explore the whole search space. beta : float Linear visibility coefficient in [0.1, 1.5]. Lower value indicates that the fireflies are less attracted to each other. alpha : float Coefficient in [0, 0.1] that is a portion of each dimension's bound widths to use for the random walk. gamma : float Exponential visibility coefficient in [0.01, 1]. Higher value indicates that the fireflies are less attracted to each other. Attributes Attribute Description best_position : dict Dictionary containing the most optimal position found during the solution iterations, with variable names as keys and corresponding position values as values. best_value : float Most optimal function value found during the solution iterations. completed_iter : int Number of iterations completed during the solution process. results : pd.DataFrame DataFrame of results throughout the iterations. For each iteration, the function value and position for each member of the population are provided. Methods .optimize ( find_minimum, max_iter=None, max_function_evals=None, max_unchanged_iter=None, sol_threshold=None ) Executes the algorithm solution with the current parameters. Results will be stored to the class attributes. Either max_iter or max_function_evals must be specified in order to prevent an endless optimization loop. If any of the criteria are met during optimization, the process is terminated. Argument Description find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. max_iter : int Maximum number of iterations. The algorithm will terminate after completing this many iterations. None indicates that the algorithm will not consider this. max_function_evals : int Maximum number of function evaluations. Must be greater than the size of the population (i.e. complete at least one iteration). The algorithm will terminate after completing this many function evaluations. This is a preferable metric for greedy algorithms. None indicates that the algorithm will not consider this. max_unchanged_iter : int If the solution does not improve after this many iterations, the optimization terminates. None indicates that the algorithm will not consider this. sol_threshold : float If a solution is found better than this threshold, the iterations stop. None indicates that the algorithm will not consider this. Example from optiseek.variables import var_float from optiseek.metaheuristics import firefly_algorithm from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = firefly_algorithm(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=10, sol_threshold=0.05) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.00290 best_position = {'x1': 1.0080388736395434, 'x2': 2.9699633384695314} n_iter = 6 References Firefly Algorithm on Wikipedia","title":"Firefly Algorithm"},{"location":"firefly_algorithm/#firefly-algorithm","text":"This class represents the firefly algorithm developed by Xin-She Yang. This algorithm is based on the flashing patterns and swarm behavior of fireflies. Fireflies are attracted to others based on their proximity in the search space and the brightness (function values) of others. Their movements also have a stochastic component. class optiseek.metaheuristics. firefly_algorithm ( input_function=None, var_list=None, linspaced_initial_positions=True, results_filename=None, n_fireflies=None, beta=1.0, alpha=0.05, gamma=0.5 )","title":"Firefly Algorithm"},{"location":"firefly_algorithm/#parameters","text":"All parameters are also class attributes and may be modified after instantiation. Parameter Description input_function : function Function that the algorithm will use to search for an optimum. *args will be passed to the function within the solver. var_list : list of variables List of variables (see variable types) to define the search space. These correspond to the arguments of the objective function and must be in the exact same order. linspaced_initial_positions : bool If true, creates a linearly spaced set of points in each search dimension, and the initial positions of the population are set to mutually exclusive combinations of these points. This guarantees that there will be no empty spots in a single dimension. If false, random initial positions are chosen. results_filename : string If a file name is passed (ending in '.csv'), the results will be written to this file after each function evaluation. This can noticeably slow down solution iterations for quick objective functions. For greedy functions, it can be beneficial to do this in case the script is interrupted. n_fireflies : int Number of fireflies to use in the swarm population. If set to None , the population size will be based on the heuristic 10 + 2 * sqrt(n_dims), where n_dims is the dimensionality of the search space. This is typically sufficient to explore the whole search space. beta : float Linear visibility coefficient in [0.1, 1.5]. Lower value indicates that the fireflies are less attracted to each other. alpha : float Coefficient in [0, 0.1] that is a portion of each dimension's bound widths to use for the random walk. gamma : float Exponential visibility coefficient in [0.01, 1]. Higher value indicates that the fireflies are less attracted to each other.","title":"Parameters"},{"location":"firefly_algorithm/#attributes","text":"Attribute Description best_position : dict Dictionary containing the most optimal position found during the solution iterations, with variable names as keys and corresponding position values as values. best_value : float Most optimal function value found during the solution iterations. completed_iter : int Number of iterations completed during the solution process. results : pd.DataFrame DataFrame of results throughout the iterations. For each iteration, the function value and position for each member of the population are provided.","title":"Attributes"},{"location":"firefly_algorithm/#methods","text":".optimize ( find_minimum, max_iter=None, max_function_evals=None, max_unchanged_iter=None, sol_threshold=None ) Executes the algorithm solution with the current parameters. Results will be stored to the class attributes. Either max_iter or max_function_evals must be specified in order to prevent an endless optimization loop. If any of the criteria are met during optimization, the process is terminated. Argument Description find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. max_iter : int Maximum number of iterations. The algorithm will terminate after completing this many iterations. None indicates that the algorithm will not consider this. max_function_evals : int Maximum number of function evaluations. Must be greater than the size of the population (i.e. complete at least one iteration). The algorithm will terminate after completing this many function evaluations. This is a preferable metric for greedy algorithms. None indicates that the algorithm will not consider this. max_unchanged_iter : int If the solution does not improve after this many iterations, the optimization terminates. None indicates that the algorithm will not consider this. sol_threshold : float If a solution is found better than this threshold, the iterations stop. None indicates that the algorithm will not consider this.","title":"Methods"},{"location":"firefly_algorithm/#example","text":"from optiseek.variables import var_float from optiseek.metaheuristics import firefly_algorithm from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = firefly_algorithm(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=10, sol_threshold=0.05) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.00290 best_position = {'x1': 1.0080388736395434, 'x2': 2.9699633384695314} n_iter = 6","title":"Example"},{"location":"firefly_algorithm/#references","text":"Firefly Algorithm on Wikipedia","title":"References"},{"location":"flying_foxes_algorithm/","text":"Flying Foxes Algorithm This class represents the flying foxes optimization algorithm developed by Zervoudakis and Tsafarakis. This algorithm is a powerful and efficient metaheuristic that takes inspiration from the group behavior of flying foxes during a heatwave. It also contains traits of other common algorithms like genetic algorithms, which are utilized during the creation of new foxes. Foxes near the coolest spot are encouraged to explore nearby areas, preserving the exploration of the search area. If the most optimal spot currently known gets too crowded, the foxes will die off and produce new ones, similar to the overheating that occurs in nature when they crowd around cool areas during a heatwave. This algorithm is unique in the fact that it requires no user input for parameters; instead, a fuzzy self-tuning technique is utilized to tune the algorithm parameters for each individual fox at the beginning of every iteration. This makes the algorithm simple to deploy even by inexperienced users. It also outperforms most population-based metaheuristics in many engineering problems. class optiseek.metaheuristics. flying_foxes_algorithm ( input_function=None, var_list=None, linspaced_initial_positions=True, results_filename=None ) Parameters All parameters are also class attributes and may be modified after instantiation. Parameter Description input_function : function Function that the algorithm will use to search for an optimum. *args will be passed to the function within the solver. var_list : list of variables List of variables (see variable types) to define the search space. These correspond to the arguments of the objective function and must be in the exact same order. linspaced_initial_positions : bool If true, creates a linearly spaced set of points in each search dimension, and the initial positions of the population are set to mutually exclusive combinations of these points. This guarantees that there will be no empty spots in a single dimension. If false, random initial positions are chosen. results_filename : string If a file name is passed (ending in '.csv'), the results will be written to this file after each function evaluation. This can noticeably slow down solution iterations for quick objective functions. For greedy functions, it can be beneficial to do this in case the script is interrupted. Attributes Attribute Description best_position : dict Dictionary containing the most optimal position found during the solution iterations, with variable names as keys and corresponding position values as values. best_value : float Most optimal function value found during the solution iterations. completed_iter : int Number of iterations completed during the solution process. results : pd.DataFrame DataFrame of results throughout the iterations. For each iteration, the function value and position for each member of the population are provided. Methods .optimize ( find_minimum, max_iter=None, max_function_evals=None, max_unchanged_iter=None, sol_threshold=None ) Executes the algorithm solution with the current parameters. Results will be stored to the class attributes. Either max_iter or max_function_evals must be specified in order to prevent an endless optimization loop. If any of the criteria are met during optimization, the process is terminated. Argument Description find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. max_iter : int Maximum number of iterations. The algorithm will terminate after completing this many iterations. None indicates that the algorithm will not consider this. max_function_evals : int Maximum number of function evaluations. Must be greater than the size of the population (i.e. complete at least one iteration). The algorithm will terminate after completing this many function evaluations. This is a preferable metric for greedy algorithms. None indicates that the algorithm will not consider this. max_unchanged_iter : int If the solution does not improve after this many iterations, the optimization terminates. None indicates that the algorithm will not consider this. sol_threshold : float If a solution is found better than this threshold, the iterations stop. None indicates that the algorithm will not consider this. Example from optiseek.variables import var_float from optiseek.metaheuristics import flying_foxes_algorithm from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = flying_foxes_algorithm(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=10, sol_threshold=0.05) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.00759 best_position = {'x1': 1.0277309595786366, 'x2': 2.9425815617892597} n_iter = 7 References A global optimizer inspired from the survival strategies of flying foxes, by Zervoudakis and Tsafarakis","title":"Flying Foxes Algorithm"},{"location":"flying_foxes_algorithm/#flying-foxes-algorithm","text":"This class represents the flying foxes optimization algorithm developed by Zervoudakis and Tsafarakis. This algorithm is a powerful and efficient metaheuristic that takes inspiration from the group behavior of flying foxes during a heatwave. It also contains traits of other common algorithms like genetic algorithms, which are utilized during the creation of new foxes. Foxes near the coolest spot are encouraged to explore nearby areas, preserving the exploration of the search area. If the most optimal spot currently known gets too crowded, the foxes will die off and produce new ones, similar to the overheating that occurs in nature when they crowd around cool areas during a heatwave. This algorithm is unique in the fact that it requires no user input for parameters; instead, a fuzzy self-tuning technique is utilized to tune the algorithm parameters for each individual fox at the beginning of every iteration. This makes the algorithm simple to deploy even by inexperienced users. It also outperforms most population-based metaheuristics in many engineering problems. class optiseek.metaheuristics. flying_foxes_algorithm ( input_function=None, var_list=None, linspaced_initial_positions=True, results_filename=None )","title":"Flying Foxes Algorithm"},{"location":"flying_foxes_algorithm/#parameters","text":"All parameters are also class attributes and may be modified after instantiation. Parameter Description input_function : function Function that the algorithm will use to search for an optimum. *args will be passed to the function within the solver. var_list : list of variables List of variables (see variable types) to define the search space. These correspond to the arguments of the objective function and must be in the exact same order. linspaced_initial_positions : bool If true, creates a linearly spaced set of points in each search dimension, and the initial positions of the population are set to mutually exclusive combinations of these points. This guarantees that there will be no empty spots in a single dimension. If false, random initial positions are chosen. results_filename : string If a file name is passed (ending in '.csv'), the results will be written to this file after each function evaluation. This can noticeably slow down solution iterations for quick objective functions. For greedy functions, it can be beneficial to do this in case the script is interrupted.","title":"Parameters"},{"location":"flying_foxes_algorithm/#attributes","text":"Attribute Description best_position : dict Dictionary containing the most optimal position found during the solution iterations, with variable names as keys and corresponding position values as values. best_value : float Most optimal function value found during the solution iterations. completed_iter : int Number of iterations completed during the solution process. results : pd.DataFrame DataFrame of results throughout the iterations. For each iteration, the function value and position for each member of the population are provided.","title":"Attributes"},{"location":"flying_foxes_algorithm/#methods","text":".optimize ( find_minimum, max_iter=None, max_function_evals=None, max_unchanged_iter=None, sol_threshold=None ) Executes the algorithm solution with the current parameters. Results will be stored to the class attributes. Either max_iter or max_function_evals must be specified in order to prevent an endless optimization loop. If any of the criteria are met during optimization, the process is terminated. Argument Description find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. max_iter : int Maximum number of iterations. The algorithm will terminate after completing this many iterations. None indicates that the algorithm will not consider this. max_function_evals : int Maximum number of function evaluations. Must be greater than the size of the population (i.e. complete at least one iteration). The algorithm will terminate after completing this many function evaluations. This is a preferable metric for greedy algorithms. None indicates that the algorithm will not consider this. max_unchanged_iter : int If the solution does not improve after this many iterations, the optimization terminates. None indicates that the algorithm will not consider this. sol_threshold : float If a solution is found better than this threshold, the iterations stop. None indicates that the algorithm will not consider this.","title":"Methods"},{"location":"flying_foxes_algorithm/#example","text":"from optiseek.variables import var_float from optiseek.metaheuristics import flying_foxes_algorithm from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = flying_foxes_algorithm(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=10, sol_threshold=0.05) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.00759 best_position = {'x1': 1.0277309595786366, 'x2': 2.9425815617892597} n_iter = 7","title":"Example"},{"location":"flying_foxes_algorithm/#references","text":"A global optimizer inspired from the survival strategies of flying foxes, by Zervoudakis and Tsafarakis","title":"References"},{"location":"mayfly_algorithm/","text":"Mayfly Algorithm This class represents the mayfly algorithm developed by Zervoudakis and Tsafarakis. This algorithm takes components from swarm-based algorithms as well as genetic algorithms and combines them into a powerful hybrid algorithm based on the mating behavior of mayflies. An initial population is split into males and females, each moving in different ways. The males exhibit swarm behavior to gather towards the best male (at the best function value), similar to particle swarm optimization. The females are attracted to a matched male if the male has a better function value. In each iteration, there is a genetic crossover between the males and females and selection of the best in the population takes place. Stochastic components are introduced into the movements to avoid local optima. class optiseek.metaheuristics. mayfly_algorithm ( input_function=None, var_list=None, linspaced_initial_positions=True, results_filename=None, n_mayflies=None, beta=0.7, gravity=0.6, alpha_cog=0.5, alpha_soc=1.5, alpha_attract=1.5, nuptial_coeff=0.05 ) Parameters All parameters are also class attributes and may be modified after instantiation. Parameter Description input_function : function Function that the algorithm will use to search for an optimum. *args will be passed to the function within the solver. var_list : list of variables List of variables (see variable types) to define the search space. These correspond to the arguments of the objective function and must be in the exact same order. linspaced_initial_positions : bool If true, creates a linearly spaced set of points in each search dimension, and the initial positions of the population are set to mutually exclusive combinations of these points. This guarantees that there will be no empty spots in a single dimension. If false, random initial positions are chosen. results_filename : string If a file name is passed (ending in '.csv'), the results will be written to this file after each function evaluation. This can noticeably slow down solution iterations for quick objective functions. For greedy functions, it can be beneficial to do this in case the script is interrupted. n_mayflies : int Number of mayflies to use in the population. If set to None , the population size will be based on the heuristic 10 + 2 * sqrt(n_dims), where n_dims is the dimensionality of the search space. This is typically sufficient to explore the whole search space. beta : float Exponential visibility coefficient in [0.1, 1]. Higher value means that mayflies are less drawn towards others. gravity : float Gravity coefficient in [0.1, 1]. Lower value means that the mayflies have less momentum. alpha_cog : float Cognitive coefficient in [0, 2]. Indicates how attracted the male mayflies are to their individually best known position. alpha_soc : float Social coefficient in [0, 2]. Indicates how attracted the male mayflies are to the male swarm's best known position. alpha_attract : float Attraction coefficient in [0, 2]. Indicates how attracted the females are to their matched male counterpart. nuptial_coeff : float Nuptial coefficient in [0, 0.4], a multiplier on bound widths for each dimension used for the male and female random walks. Attributes Attribute Description best_position : dict Dictionary containing the most optimal position found during the solution iterations, with variable names as keys and corresponding position values as values. best_value : float Most optimal function value found during the solution iterations. completed_iter : int Number of iterations completed during the solution process. results : pd.DataFrame DataFrame of results throughout the iterations. For each iteration, the function value and position for each member of the population are provided. Methods .optimize ( find_minimum, max_iter=None, max_function_evals=None, max_unchanged_iter=None, sol_threshold=None ) Executes the algorithm solution with the current parameters. Results will be stored to the class attributes. Either max_iter or max_function_evals must be specified in order to prevent an endless optimization loop. If any of the criteria are met during optimization, the process is terminated. Argument Description find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. max_iter : int Maximum number of iterations. The algorithm will terminate after completing this many iterations. None indicates that the algorithm will not consider this. max_function_evals : int Maximum number of function evaluations. Must be greater than the size of the population (i.e. complete at least one iteration). The algorithm will terminate after completing this many function evaluations. This is a preferable metric for greedy algorithms. None indicates that the algorithm will not consider this. max_unchanged_iter : int If the solution does not improve after this many iterations, the optimization terminates. None indicates that the algorithm will not consider this. sol_threshold : float If a solution is found better than this threshold, the iterations stop. None indicates that the algorithm will not consider this. Example from optiseek.variables import var_float from optiseek.metaheuristics import mayfly_algorithm from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = mayfly_algorithm(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=10, sol_threshold=0.05) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.04024 best_position = {'x1': 1.000108782682335, 'x2': 3.0896223872777275} n_iter = 9 References A mayfly optimization algorithm, by Zervoudakis and Tsafarakis","title":"Mayfly Algorithm"},{"location":"mayfly_algorithm/#mayfly-algorithm","text":"This class represents the mayfly algorithm developed by Zervoudakis and Tsafarakis. This algorithm takes components from swarm-based algorithms as well as genetic algorithms and combines them into a powerful hybrid algorithm based on the mating behavior of mayflies. An initial population is split into males and females, each moving in different ways. The males exhibit swarm behavior to gather towards the best male (at the best function value), similar to particle swarm optimization. The females are attracted to a matched male if the male has a better function value. In each iteration, there is a genetic crossover between the males and females and selection of the best in the population takes place. Stochastic components are introduced into the movements to avoid local optima. class optiseek.metaheuristics. mayfly_algorithm ( input_function=None, var_list=None, linspaced_initial_positions=True, results_filename=None, n_mayflies=None, beta=0.7, gravity=0.6, alpha_cog=0.5, alpha_soc=1.5, alpha_attract=1.5, nuptial_coeff=0.05 )","title":"Mayfly Algorithm"},{"location":"mayfly_algorithm/#parameters","text":"All parameters are also class attributes and may be modified after instantiation. Parameter Description input_function : function Function that the algorithm will use to search for an optimum. *args will be passed to the function within the solver. var_list : list of variables List of variables (see variable types) to define the search space. These correspond to the arguments of the objective function and must be in the exact same order. linspaced_initial_positions : bool If true, creates a linearly spaced set of points in each search dimension, and the initial positions of the population are set to mutually exclusive combinations of these points. This guarantees that there will be no empty spots in a single dimension. If false, random initial positions are chosen. results_filename : string If a file name is passed (ending in '.csv'), the results will be written to this file after each function evaluation. This can noticeably slow down solution iterations for quick objective functions. For greedy functions, it can be beneficial to do this in case the script is interrupted. n_mayflies : int Number of mayflies to use in the population. If set to None , the population size will be based on the heuristic 10 + 2 * sqrt(n_dims), where n_dims is the dimensionality of the search space. This is typically sufficient to explore the whole search space. beta : float Exponential visibility coefficient in [0.1, 1]. Higher value means that mayflies are less drawn towards others. gravity : float Gravity coefficient in [0.1, 1]. Lower value means that the mayflies have less momentum. alpha_cog : float Cognitive coefficient in [0, 2]. Indicates how attracted the male mayflies are to their individually best known position. alpha_soc : float Social coefficient in [0, 2]. Indicates how attracted the male mayflies are to the male swarm's best known position. alpha_attract : float Attraction coefficient in [0, 2]. Indicates how attracted the females are to their matched male counterpart. nuptial_coeff : float Nuptial coefficient in [0, 0.4], a multiplier on bound widths for each dimension used for the male and female random walks.","title":"Parameters"},{"location":"mayfly_algorithm/#attributes","text":"Attribute Description best_position : dict Dictionary containing the most optimal position found during the solution iterations, with variable names as keys and corresponding position values as values. best_value : float Most optimal function value found during the solution iterations. completed_iter : int Number of iterations completed during the solution process. results : pd.DataFrame DataFrame of results throughout the iterations. For each iteration, the function value and position for each member of the population are provided.","title":"Attributes"},{"location":"mayfly_algorithm/#methods","text":".optimize ( find_minimum, max_iter=None, max_function_evals=None, max_unchanged_iter=None, sol_threshold=None ) Executes the algorithm solution with the current parameters. Results will be stored to the class attributes. Either max_iter or max_function_evals must be specified in order to prevent an endless optimization loop. If any of the criteria are met during optimization, the process is terminated. Argument Description find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. max_iter : int Maximum number of iterations. The algorithm will terminate after completing this many iterations. None indicates that the algorithm will not consider this. max_function_evals : int Maximum number of function evaluations. Must be greater than the size of the population (i.e. complete at least one iteration). The algorithm will terminate after completing this many function evaluations. This is a preferable metric for greedy algorithms. None indicates that the algorithm will not consider this. max_unchanged_iter : int If the solution does not improve after this many iterations, the optimization terminates. None indicates that the algorithm will not consider this. sol_threshold : float If a solution is found better than this threshold, the iterations stop. None indicates that the algorithm will not consider this.","title":"Methods"},{"location":"mayfly_algorithm/#example","text":"from optiseek.variables import var_float from optiseek.metaheuristics import mayfly_algorithm from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = mayfly_algorithm(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=10, sol_threshold=0.05) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.04024 best_position = {'x1': 1.000108782682335, 'x2': 3.0896223872777275} n_iter = 9","title":"Example"},{"location":"mayfly_algorithm/#references","text":"A mayfly optimization algorithm, by Zervoudakis and Tsafarakis","title":"References"},{"location":"parameter_grid_search/","text":"Parameter Grid Search The purpose of the grid search is to provide an easy way to tune parameters for a given algorithm in a way that will work well on a certain class of problem. This is accomplished by creating a grid of parameter permutations based on user input and running a selected algorithm with those parameters to find the best set. The best results of every permutation of parameters are saved for post-processing. class optiseek.modelhelpers. parameter_grid_search ( algorithm, input_function, var_list, param_grid, optimize_options, show_progress=False ) Parameters Parameter Description algorithm : class Class of the algorithm that you would like to use. input_function : function Function object for the algorithm to optimize. var_list : list of variables List of all variable objects to define their names and domains in the search space. This is the same list you would pass to the optimization algorithm class. param_grid : dict Dictionary containing the grid of parameters to be explored with the parameter names (strings) as keys and a list of parameter values as values. All permutations of parameters in this dict will be tested. For any parameters not specified, the default will be used. See the example for more details. optimize_options : dict Dictionary containing the kwargs for the optimize() method of the algorithm. show_progress : bool Boolean to indicate whether the grid search will print progress to the console as the solve continues. The number of permutations increases exponentially with respect to parameter inputs, so for high numbers of parameter inputs, this can be useful to see how much longer the solver has left. Attributes Attribute Description best_parameters : dict A dictionary containing the best performing set of parameters. The parameter names as strings are stored as keys and the corresponding values are stored as values. best_position : list or ndarray The most optimal position that was found using the best performing parameters. best_value : float The most optimal function value that was found using the best performing parameters. results : pd.DataFrame A pandas DataFrame containing all results from the search. Columns represent the algorithm parameters, best position found, and best function value found with the respective parameters. Methods .search () Executes the parameter grid search process and stores the results in the class attributes. Example from optiseek.variables import var_float from optiseek.modelhelpers import parameter_grid_search from optiseek.metaheuristics import particle_swarm_optimizer from optiseek.testfunctions import ackley # define the variables for the Ackley2D function var_list = [ var_float('x', [-10, 10]), var_float('y', [-10, 10]) ] # set up the param_grid dictionary param_grid = { 'n_particles': [10], 'weight': [0.20, 0.35, 0.50], 'phi_p': [1.0, 1.5, 2.0], 'phi_g': [1.0, 1.5, 2.0], 'zero_velocity': [True, False] } # set up the optimize_options dictionary optimize_options = { 'find_minimum': True, 'max_function_evals': 75 } # create the an instance of the grid search class pgs = parameter_grid_search(particle_swarm_optimizer, ackley, var_list, param_grid, optimize_options) # start the search pgs.search() # show the optimal parameters, the best function value found, and a preview of all saved results print(f'best parameters: {pgs.best_parameters}') print(f'best value: {pgs.best_value}\\n') print(pgs.results.head()) best parameters: {'n_particles': 10, 'weight': 0.2, 'phi_p': 1.5, 'phi_g': 1.0, 'zero_velocity': False} best value: 0.026961543641856878 n_particles weight phi_p ... x y best_value 0 10 0.20 1.5 ... 0.007717 0.004236 0.026962 1 10 0.50 1.0 ... 0.021830 -0.003103 0.075259 2 10 0.20 2.0 ... 0.019337 -0.018130 0.093595 3 10 0.35 1.0 ... -0.028123 0.002833 0.101083 4 10 0.20 1.5 ... 0.001063 0.031908 0.117212 [5 rows x 8 columns]","title":"Parameter Grid Search"},{"location":"parameter_grid_search/#parameter-grid-search","text":"The purpose of the grid search is to provide an easy way to tune parameters for a given algorithm in a way that will work well on a certain class of problem. This is accomplished by creating a grid of parameter permutations based on user input and running a selected algorithm with those parameters to find the best set. The best results of every permutation of parameters are saved for post-processing. class optiseek.modelhelpers. parameter_grid_search ( algorithm, input_function, var_list, param_grid, optimize_options, show_progress=False )","title":"Parameter Grid Search"},{"location":"parameter_grid_search/#parameters","text":"Parameter Description algorithm : class Class of the algorithm that you would like to use. input_function : function Function object for the algorithm to optimize. var_list : list of variables List of all variable objects to define their names and domains in the search space. This is the same list you would pass to the optimization algorithm class. param_grid : dict Dictionary containing the grid of parameters to be explored with the parameter names (strings) as keys and a list of parameter values as values. All permutations of parameters in this dict will be tested. For any parameters not specified, the default will be used. See the example for more details. optimize_options : dict Dictionary containing the kwargs for the optimize() method of the algorithm. show_progress : bool Boolean to indicate whether the grid search will print progress to the console as the solve continues. The number of permutations increases exponentially with respect to parameter inputs, so for high numbers of parameter inputs, this can be useful to see how much longer the solver has left.","title":"Parameters"},{"location":"parameter_grid_search/#attributes","text":"Attribute Description best_parameters : dict A dictionary containing the best performing set of parameters. The parameter names as strings are stored as keys and the corresponding values are stored as values. best_position : list or ndarray The most optimal position that was found using the best performing parameters. best_value : float The most optimal function value that was found using the best performing parameters. results : pd.DataFrame A pandas DataFrame containing all results from the search. Columns represent the algorithm parameters, best position found, and best function value found with the respective parameters.","title":"Attributes"},{"location":"parameter_grid_search/#methods","text":".search () Executes the parameter grid search process and stores the results in the class attributes.","title":"Methods"},{"location":"parameter_grid_search/#example","text":"from optiseek.variables import var_float from optiseek.modelhelpers import parameter_grid_search from optiseek.metaheuristics import particle_swarm_optimizer from optiseek.testfunctions import ackley # define the variables for the Ackley2D function var_list = [ var_float('x', [-10, 10]), var_float('y', [-10, 10]) ] # set up the param_grid dictionary param_grid = { 'n_particles': [10], 'weight': [0.20, 0.35, 0.50], 'phi_p': [1.0, 1.5, 2.0], 'phi_g': [1.0, 1.5, 2.0], 'zero_velocity': [True, False] } # set up the optimize_options dictionary optimize_options = { 'find_minimum': True, 'max_function_evals': 75 } # create the an instance of the grid search class pgs = parameter_grid_search(particle_swarm_optimizer, ackley, var_list, param_grid, optimize_options) # start the search pgs.search() # show the optimal parameters, the best function value found, and a preview of all saved results print(f'best parameters: {pgs.best_parameters}') print(f'best value: {pgs.best_value}\\n') print(pgs.results.head()) best parameters: {'n_particles': 10, 'weight': 0.2, 'phi_p': 1.5, 'phi_g': 1.0, 'zero_velocity': False} best value: 0.026961543641856878 n_particles weight phi_p ... x y best_value 0 10 0.20 1.5 ... 0.007717 0.004236 0.026962 1 10 0.50 1.0 ... 0.021830 -0.003103 0.075259 2 10 0.20 2.0 ... 0.019337 -0.018130 0.093595 3 10 0.35 1.0 ... -0.028123 0.002833 0.101083 4 10 0.20 1.5 ... 0.001063 0.031908 0.117212 [5 rows x 8 columns]","title":"Example"},{"location":"particle_swarm_optimization/","text":"Particle Swarm Optimizer This class represents a standard particle swarm optimization algorithm, originally developed by Kennedy and Eberhart. This algorithm is based on swarm behavior commonly observed in nature. A population of particles is introduced to traverse the search space. Their movement is influenced by their own previous positions, the best known position of the swarm, and some stochastic velocity. class optiseek.metaheuristics. particle_swarm_optimizer ( input_function=None, var_list=None, linspaced_initial_positions=True, results_filename=None, n_particles=None, weight=0.35, phi_p=1.5, phi_g=1.5, zero_velocity=False ) Parameters All parameters are also class attributes and may be modified after instantiation. Parameter Description input_function : function Function that the algorithm will use to search for an optimum. *args will be passed to the function within the solver. var_list : list of variables List of variables (see variable types) to define the search space. These correspond to the arguments of the objective function and must be in the exact same order. linspaced_initial_positions : bool If true, creates a linearly spaced set of points in each search dimension, and the initial positions of the population are set to mutually exclusive combinations of these points. This guarantees that there will be no empty spots in a single dimension. If false, random initial positions are chosen. results_filename : string If a file name is passed (ending in '.csv'), the results will be written to this file after each function evaluation. This can noticeably slow down solution iterations for quick objective functions. For greedy functions, it can be beneficial to do this in case the script is interrupted. n_particles : int Number of particles to use in the particle swarm population. If set to None , the population size will be based on the heuristic 10 + 2 * sqrt(n_dims), where n_dims is the dimensionality of the search space. This is typically sufficient to explore the whole search space. weight : float Weight coefficient in [0, 1]. Lower weight gives the particles less momentum. phi_p : float Cognitive coefficient in [0, 3]. Higher value indicates that the particles are drawn more towards their own best known position. phi_g : float Social coefficient in [0, 3]. Higher value indicates that the particles are drawn more towards the swarm's collectively best known position. zero_velocity : bool Choose whether the particles start off with zero velocity or a random initial velocity. Attributes Attribute Description best_position : dict Dictionary containing the most optimal position found during the solution iterations, with variable names as keys and corresponding position values as values. best_value : float Most optimal function value found during the solution iterations. completed_iter : int Number of iterations completed during the solution process. results : pd.DataFrame DataFrame of results throughout the iterations. For each iteration, the function value and position for each member of the population are provided. Methods .optimize ( find_minimum, max_iter=None, max_function_evals=None, max_unchanged_iter=None, sol_threshold=None ) Executes the algorithm solution with the current parameters. Results will be stored to the class attributes. Either max_iter or max_function_evals must be specified in order to prevent an endless optimization loop. If any of the criteria are met during optimization, the process is terminated. Argument Description find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. max_iter : int Maximum number of iterations. The algorithm will terminate after completing this many iterations. None indicates that the algorithm will not consider this. max_function_evals : int Maximum number of function evaluations. Must be greater than the size of the population (i.e. complete at least one iteration). The algorithm will terminate after completing this many function evaluations. This is a preferable metric for greedy algorithms. None indicates that the algorithm will not consider this. max_unchanged_iter : int If the solution does not improve after this many iterations, the optimization terminates. None indicates that the algorithm will not consider this. sol_threshold : float If a solution is found better than this threshold, the iterations stop. None indicates that the algorithm will not consider this. Example from optiseek.variables import var_float from optiseek.metaheuristics import particle_swarm_optimizer from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = particle_swarm_optimizer(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=10, sol_threshold=0.05) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.04470 best_position = {'x1': 1.050827859446013, 'x2': 2.86984154026157} n_iter = 8 References Particle Swarm Optimization on Wikipedia","title":"Particle Swarm Optimizer"},{"location":"particle_swarm_optimization/#particle-swarm-optimizer","text":"This class represents a standard particle swarm optimization algorithm, originally developed by Kennedy and Eberhart. This algorithm is based on swarm behavior commonly observed in nature. A population of particles is introduced to traverse the search space. Their movement is influenced by their own previous positions, the best known position of the swarm, and some stochastic velocity. class optiseek.metaheuristics. particle_swarm_optimizer ( input_function=None, var_list=None, linspaced_initial_positions=True, results_filename=None, n_particles=None, weight=0.35, phi_p=1.5, phi_g=1.5, zero_velocity=False )","title":"Particle Swarm Optimizer"},{"location":"particle_swarm_optimization/#parameters","text":"All parameters are also class attributes and may be modified after instantiation. Parameter Description input_function : function Function that the algorithm will use to search for an optimum. *args will be passed to the function within the solver. var_list : list of variables List of variables (see variable types) to define the search space. These correspond to the arguments of the objective function and must be in the exact same order. linspaced_initial_positions : bool If true, creates a linearly spaced set of points in each search dimension, and the initial positions of the population are set to mutually exclusive combinations of these points. This guarantees that there will be no empty spots in a single dimension. If false, random initial positions are chosen. results_filename : string If a file name is passed (ending in '.csv'), the results will be written to this file after each function evaluation. This can noticeably slow down solution iterations for quick objective functions. For greedy functions, it can be beneficial to do this in case the script is interrupted. n_particles : int Number of particles to use in the particle swarm population. If set to None , the population size will be based on the heuristic 10 + 2 * sqrt(n_dims), where n_dims is the dimensionality of the search space. This is typically sufficient to explore the whole search space. weight : float Weight coefficient in [0, 1]. Lower weight gives the particles less momentum. phi_p : float Cognitive coefficient in [0, 3]. Higher value indicates that the particles are drawn more towards their own best known position. phi_g : float Social coefficient in [0, 3]. Higher value indicates that the particles are drawn more towards the swarm's collectively best known position. zero_velocity : bool Choose whether the particles start off with zero velocity or a random initial velocity.","title":"Parameters"},{"location":"particle_swarm_optimization/#attributes","text":"Attribute Description best_position : dict Dictionary containing the most optimal position found during the solution iterations, with variable names as keys and corresponding position values as values. best_value : float Most optimal function value found during the solution iterations. completed_iter : int Number of iterations completed during the solution process. results : pd.DataFrame DataFrame of results throughout the iterations. For each iteration, the function value and position for each member of the population are provided.","title":"Attributes"},{"location":"particle_swarm_optimization/#methods","text":".optimize ( find_minimum, max_iter=None, max_function_evals=None, max_unchanged_iter=None, sol_threshold=None ) Executes the algorithm solution with the current parameters. Results will be stored to the class attributes. Either max_iter or max_function_evals must be specified in order to prevent an endless optimization loop. If any of the criteria are met during optimization, the process is terminated. Argument Description find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. max_iter : int Maximum number of iterations. The algorithm will terminate after completing this many iterations. None indicates that the algorithm will not consider this. max_function_evals : int Maximum number of function evaluations. Must be greater than the size of the population (i.e. complete at least one iteration). The algorithm will terminate after completing this many function evaluations. This is a preferable metric for greedy algorithms. None indicates that the algorithm will not consider this. max_unchanged_iter : int If the solution does not improve after this many iterations, the optimization terminates. None indicates that the algorithm will not consider this. sol_threshold : float If a solution is found better than this threshold, the iterations stop. None indicates that the algorithm will not consider this.","title":"Methods"},{"location":"particle_swarm_optimization/#example","text":"from optiseek.variables import var_float from optiseek.metaheuristics import particle_swarm_optimizer from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = particle_swarm_optimizer(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=10, sol_threshold=0.05) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.04470 best_position = {'x1': 1.050827859446013, 'x2': 2.86984154026157} n_iter = 8","title":"Example"},{"location":"particle_swarm_optimization/#references","text":"Particle Swarm Optimization on Wikipedia","title":"References"},{"location":"penalty_constraints/","text":"Penalty Constraints This function allows the user to apply constraints to an objective function as penalties and will return a new penalized function that can be optimized. Both counted penalties and quadratic penalties can be enforced with this function. Shown below is a representation of a 1D function f(x) and how it is penalized by both counted and quadratic constraints. In this case, the constraints are that the function input x cannot be less than A or greater than B . With either of these constraint types, as soon as a constraint is violated, the function value y has a penalty added to it. For the quadratic penalty, this penalty increases quadratically by the magnitude that the constraint is violated by. For the counted penalty, there is a fixed amount added to the function value for every penalty that is broken, regardless of the magnitude it is violated by. It should be noted that the counted penalty creates a sharp discontinuity in the function, while the quadratic penalty is smooth. Typically, use of the quadratic penalty will result in better convergence of the optimization algorithm; however, there are situations where the function value is optimal at the location where a constraint is applied (like at A in the graphic above). In this case, the quadratic penalty multiplier will need to approach infinity in order for the constraint to be properly enforced. In situations like this, it may be beneficial to use a moderate quadratic penalty with a small counted penalty. Applying penalty constraints does not guarantee that the optimization algorithm will converge at a point within the constraints. Oftentimes, the penalty multipliers must be tuned by the user to find out what works best. Parameters of the optiseek penalty_constraints function allow the user to control the magnitude of each of these penalties. Combinations of both of these penalty types can be applied at once with a single penalty_constraints function call. A value of zero will result in no penalty of that type being applied to the returned penalized function. A higher value increases the step height for count penalties and increases the slope for quadratic penalties. This tool will work for any function, whether the user would like to find the minimum or maximum. function optiseek.modelhelpers. penalty_constraints ( input_function, constraint_dict, find_minimum=True, p_quadratic=1, p_count=0 ) Parameters Parameter Description input_function : function Function object for the algorithm to optimize. constraint_dict : dict A dictionary that contains any number of constraint equations to be applied to the input function. The dictionary is structured like {constraint function: constraint type} where the constraints are compared to zero with a mathematical operator: g1(x) = 0, g2(x) < 0, etc. The constraint function must share the same arguments in the same order as the objective function. The constraint type must be one of the following strings: \"<\", \"<=\", \">\", \">=\", \"=\". See the example for more information. find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. p_quadratic : float Penalty multiplier for the quadratic penalty in [0, inf]. A value of zero will result in no quadratic penalty to the objective function. A nonzero value smoothly penalizes the function according to the magnitude that the constraint is broken. Default value is 1. p_count : float Penalty multiplier for the count penalty in [0, inf]. A value of zero will result in no count penalty to the objective function. A nonzero value creates a sharp discontinuity where the constraint is broken. Default value is 0. Returns Returns Description penalized_function : function A function representing the input objective function with the constraints applied as penalties to the function value. check_constraints : function A function that, when passed some inputs, returns a list of booleans that represent whether each constraint was satisfied (True) or broken (False). Inputs to this function are the exact same as the input function. Example 1: We can demonstrate these constraints on a problem with several complex constraint equations to see it in action! Shown below is an engineering optimization problem taken from an article by Xin-She Yang (see references) based on the properties of a spring. The function, its constraints, and the variable bounds are given. Note that in this example, we choose to use a quadratic penalty multiplier of 2 and no counted penalty at all. Also note that the constraint functions must share the same arguments in the same order as the input function. from optiseek.variables import var_float from optiseek.modelhelpers import penalty_constraints from optiseek.metaheuristics import flying_foxes_algorithm # create the function definition def spring_problem(x1, x2, x3): return x1 ** 2 * x2 * (2 + x3) # create the constraints as functions def g1(x1, x2, x3): return 1 - (x2 ** 3 * x3) / (71785 * x1 ** 4) def g2(x1, x2, x3): return (4 * x2 ** 2 - x1 * x2) / (12566 * (x1 ** 3 * x2 - x1 ** 4)) + 1 / (5108 * x1 ** 2) - 1 def g3(x1, x2, x3): return 1 - (140.45 * x1) / (x2 ** 3 * x3) def g4(x1, x2, x3): return (x1 + x2) / 1.5 - 1 # create the constraint dictionary to define the constraint type spring_constraint_dict = {g1: \"<=\", g2: \"<=\", g3: \"<=\", g4: \"<=\"} # create a constrained version of the original function to be optimized spring_problem_const, const_check = penalty_constraints(spring_problem, spring_constraint_dict, find_minimum=True, p_quadratic=5000, p_count=0) # define variable list and search domain var_list = [ var_float('x1', [0.05, 2.0]), var_float('x2', [0.25, 1.3]), var_float('x3', [2.0, 15.0]) ] # instantiate an optimization algorithm with the constrained function and search domain alg = flying_foxes_algorithm(spring_problem_const, var_list) # optimize and check to make sure constraints are satisfied alg.optimize(find_minimum=True, max_iter=500) constraint_bools = const_check(*alg.best_position.values()) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') print(f'constraint check: {constraint_bools}') best_value = 0.01267 best_position = {'x1': 0.0517568175037568, 'x2': 0.35827540281247405, 'x3': 11.201295780064102} n_iter = 500 constraint check: [True, True, True, True] With this code, the best found solution found was approximately [0.0517, 0.358, 11.20]. A very high penalty constraint value was necessary, as the constraints made the search space much more complex. We also used the constraint checking function created by the penalty_constraints helper to verify that our constraints were indeed satisfied with the best solution. Note that this is not guaranteed to be the global optimum. Example 2: In this generic problem, the constraints require a bit more work to implement. The constraint_dict parameter for the penalty constraints function requires the constraints to be compared to zero. We must re-arrange the constraint equations to ensure this. Also, we can assume an upper bound on the search domain of 20 for each variable. Note: This is a linear problem, and could be easily solved with linear programming as well. However, it is a good example for re-arranging constraint functions. First, we will re-arrange the constraints. We can use the minimum value for x, y, and z to help define the search space. from optiseek.variables import var_float from optiseek.modelhelpers import penalty_constraints from optiseek.metaheuristics import flying_foxes_algorithm # create the function definition def linear_function(x, y, z): return -2 * x - 3 * y - 4 * z # create the constraints as functions def g1(x, y, z): return 3 * x + 2 * y + z - 10 def g2(x, y, z): return 2 * x + 5 * y + 3 * z - 15 # create the constraint dictionary to define the constraint type constraint_dict = {g1: \"<=\", g2: \"<=\"} # create a constrained version of the original function to be optimized linear_function_const, const_check = penalty_constraints(linear_function, constraint_dict, p_quadratic=50000, p_count=0) # define variable list and search domain var_list = [ var_float('x', [0, 20]), var_float('y', [0, 20]), var_float('z', [0, 20]) ] # instantiate an optimization algorithm with the constrained function and search domain alg = flying_foxes_algorithm(linear_function_const, var_list) # optimize and check to make sure constraints are satisfied alg.optimize(find_minimum=True, max_iter=200) constraint_bools = const_check(*alg.best_position.values()) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') print(f'constraint check: {constraint_bools}') best_value = -19.99982 best_position = {'x': 0.0, 'y': 0.0, 'z': 4.9999547568628735} n_iter = 200 constraint check: [True, True] With this code, it can be found that the best solution is approximately f(0, 0, 5) = -20 . References Algorithms for Optimization by Kochenderfer and Wheeler, Chapter 10.7 Spring Example Problem by Xin-She Yang","title":"Penalty Constraints"},{"location":"penalty_constraints/#penalty-constraints","text":"This function allows the user to apply constraints to an objective function as penalties and will return a new penalized function that can be optimized. Both counted penalties and quadratic penalties can be enforced with this function. Shown below is a representation of a 1D function f(x) and how it is penalized by both counted and quadratic constraints. In this case, the constraints are that the function input x cannot be less than A or greater than B . With either of these constraint types, as soon as a constraint is violated, the function value y has a penalty added to it. For the quadratic penalty, this penalty increases quadratically by the magnitude that the constraint is violated by. For the counted penalty, there is a fixed amount added to the function value for every penalty that is broken, regardless of the magnitude it is violated by. It should be noted that the counted penalty creates a sharp discontinuity in the function, while the quadratic penalty is smooth. Typically, use of the quadratic penalty will result in better convergence of the optimization algorithm; however, there are situations where the function value is optimal at the location where a constraint is applied (like at A in the graphic above). In this case, the quadratic penalty multiplier will need to approach infinity in order for the constraint to be properly enforced. In situations like this, it may be beneficial to use a moderate quadratic penalty with a small counted penalty. Applying penalty constraints does not guarantee that the optimization algorithm will converge at a point within the constraints. Oftentimes, the penalty multipliers must be tuned by the user to find out what works best. Parameters of the optiseek penalty_constraints function allow the user to control the magnitude of each of these penalties. Combinations of both of these penalty types can be applied at once with a single penalty_constraints function call. A value of zero will result in no penalty of that type being applied to the returned penalized function. A higher value increases the step height for count penalties and increases the slope for quadratic penalties. This tool will work for any function, whether the user would like to find the minimum or maximum. function optiseek.modelhelpers. penalty_constraints ( input_function, constraint_dict, find_minimum=True, p_quadratic=1, p_count=0 )","title":"Penalty Constraints"},{"location":"penalty_constraints/#parameters","text":"Parameter Description input_function : function Function object for the algorithm to optimize. constraint_dict : dict A dictionary that contains any number of constraint equations to be applied to the input function. The dictionary is structured like {constraint function: constraint type} where the constraints are compared to zero with a mathematical operator: g1(x) = 0, g2(x) < 0, etc. The constraint function must share the same arguments in the same order as the objective function. The constraint type must be one of the following strings: \"<\", \"<=\", \">\", \">=\", \"=\". See the example for more information. find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. p_quadratic : float Penalty multiplier for the quadratic penalty in [0, inf]. A value of zero will result in no quadratic penalty to the objective function. A nonzero value smoothly penalizes the function according to the magnitude that the constraint is broken. Default value is 1. p_count : float Penalty multiplier for the count penalty in [0, inf]. A value of zero will result in no count penalty to the objective function. A nonzero value creates a sharp discontinuity where the constraint is broken. Default value is 0.","title":"Parameters"},{"location":"penalty_constraints/#returns","text":"Returns Description penalized_function : function A function representing the input objective function with the constraints applied as penalties to the function value. check_constraints : function A function that, when passed some inputs, returns a list of booleans that represent whether each constraint was satisfied (True) or broken (False). Inputs to this function are the exact same as the input function.","title":"Returns"},{"location":"penalty_constraints/#example-1","text":"We can demonstrate these constraints on a problem with several complex constraint equations to see it in action! Shown below is an engineering optimization problem taken from an article by Xin-She Yang (see references) based on the properties of a spring. The function, its constraints, and the variable bounds are given. Note that in this example, we choose to use a quadratic penalty multiplier of 2 and no counted penalty at all. Also note that the constraint functions must share the same arguments in the same order as the input function. from optiseek.variables import var_float from optiseek.modelhelpers import penalty_constraints from optiseek.metaheuristics import flying_foxes_algorithm # create the function definition def spring_problem(x1, x2, x3): return x1 ** 2 * x2 * (2 + x3) # create the constraints as functions def g1(x1, x2, x3): return 1 - (x2 ** 3 * x3) / (71785 * x1 ** 4) def g2(x1, x2, x3): return (4 * x2 ** 2 - x1 * x2) / (12566 * (x1 ** 3 * x2 - x1 ** 4)) + 1 / (5108 * x1 ** 2) - 1 def g3(x1, x2, x3): return 1 - (140.45 * x1) / (x2 ** 3 * x3) def g4(x1, x2, x3): return (x1 + x2) / 1.5 - 1 # create the constraint dictionary to define the constraint type spring_constraint_dict = {g1: \"<=\", g2: \"<=\", g3: \"<=\", g4: \"<=\"} # create a constrained version of the original function to be optimized spring_problem_const, const_check = penalty_constraints(spring_problem, spring_constraint_dict, find_minimum=True, p_quadratic=5000, p_count=0) # define variable list and search domain var_list = [ var_float('x1', [0.05, 2.0]), var_float('x2', [0.25, 1.3]), var_float('x3', [2.0, 15.0]) ] # instantiate an optimization algorithm with the constrained function and search domain alg = flying_foxes_algorithm(spring_problem_const, var_list) # optimize and check to make sure constraints are satisfied alg.optimize(find_minimum=True, max_iter=500) constraint_bools = const_check(*alg.best_position.values()) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') print(f'constraint check: {constraint_bools}') best_value = 0.01267 best_position = {'x1': 0.0517568175037568, 'x2': 0.35827540281247405, 'x3': 11.201295780064102} n_iter = 500 constraint check: [True, True, True, True] With this code, the best found solution found was approximately [0.0517, 0.358, 11.20]. A very high penalty constraint value was necessary, as the constraints made the search space much more complex. We also used the constraint checking function created by the penalty_constraints helper to verify that our constraints were indeed satisfied with the best solution. Note that this is not guaranteed to be the global optimum.","title":"Example 1:"},{"location":"penalty_constraints/#example-2","text":"In this generic problem, the constraints require a bit more work to implement. The constraint_dict parameter for the penalty constraints function requires the constraints to be compared to zero. We must re-arrange the constraint equations to ensure this. Also, we can assume an upper bound on the search domain of 20 for each variable. Note: This is a linear problem, and could be easily solved with linear programming as well. However, it is a good example for re-arranging constraint functions. First, we will re-arrange the constraints. We can use the minimum value for x, y, and z to help define the search space. from optiseek.variables import var_float from optiseek.modelhelpers import penalty_constraints from optiseek.metaheuristics import flying_foxes_algorithm # create the function definition def linear_function(x, y, z): return -2 * x - 3 * y - 4 * z # create the constraints as functions def g1(x, y, z): return 3 * x + 2 * y + z - 10 def g2(x, y, z): return 2 * x + 5 * y + 3 * z - 15 # create the constraint dictionary to define the constraint type constraint_dict = {g1: \"<=\", g2: \"<=\"} # create a constrained version of the original function to be optimized linear_function_const, const_check = penalty_constraints(linear_function, constraint_dict, p_quadratic=50000, p_count=0) # define variable list and search domain var_list = [ var_float('x', [0, 20]), var_float('y', [0, 20]), var_float('z', [0, 20]) ] # instantiate an optimization algorithm with the constrained function and search domain alg = flying_foxes_algorithm(linear_function_const, var_list) # optimize and check to make sure constraints are satisfied alg.optimize(find_minimum=True, max_iter=200) constraint_bools = const_check(*alg.best_position.values()) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') print(f'constraint check: {constraint_bools}') best_value = -19.99982 best_position = {'x': 0.0, 'y': 0.0, 'z': 4.9999547568628735} n_iter = 200 constraint check: [True, True] With this code, it can be found that the best solution is approximately f(0, 0, 5) = -20 .","title":"Example 2:"},{"location":"penalty_constraints/#references","text":"Algorithms for Optimization by Kochenderfer and Wheeler, Chapter 10.7 Spring Example Problem by Xin-She Yang","title":"References"},{"location":"rosenbrock/","text":"Rosenbrock Function This is a 2D function with a global minimum of zero at [1, 1]. Form of the function is as follows: function optiseek.testfunctions. rosenbrock ( x1, x2 ) Parameters Parameter Description x1 : float Input value for the first dimension. x2 : float Input value for the second dimension. Example from optiseek.testfunctions import rosenbrock y = rosenbrock(1, 1) 0 References List of Test Functions on Wikipedia","title":"Rosenbrock Function"},{"location":"rosenbrock/#rosenbrock-function","text":"This is a 2D function with a global minimum of zero at [1, 1]. Form of the function is as follows: function optiseek.testfunctions. rosenbrock ( x1, x2 )","title":"Rosenbrock Function"},{"location":"rosenbrock/#parameters","text":"Parameter Description x1 : float Input value for the first dimension. x2 : float Input value for the second dimension.","title":"Parameters"},{"location":"rosenbrock/#example","text":"from optiseek.testfunctions import rosenbrock y = rosenbrock(1, 1) 0","title":"Example"},{"location":"rosenbrock/#references","text":"List of Test Functions on Wikipedia","title":"References"},{"location":"simulated_annealing/","text":"Simulated Annealing This class represents the simulated annealing algorithm developed by Kirkpatrick et al. This is a local search method that takes inspiration from the annealing process in metals. Unlike deterministic gradient-based search methods, this algorithm has the ability to avoid being trapped in local optima. This is accomplished because there is a probability that a worse solution could be accepted during each iteration. As the iterations progress (i.e. temperature decreases), this probability diminishes and the algorithm is able to settle into what is hopefully a global optimum. class optiseek.metaheuristics. simulated_annealing ( input_function=None, var_list=None, results_filename=None, initial_guess=None, sigma_coeff=0.2, neighbor_dim_changes=-1, start_temperature=10, alpha=0.90 ) Parameters All parameters are also class attributes and may be modified after instantiation. Parameter Description input_function : function Function that the algorithm will use to search for an optimum. *args will be passed to the function within the solver. var_list : list of variables List of variables (see variable types) to define the search space. These correspond to the arguments of the objective function and must be in the exact same order. results_filename : string If a file name is passed (ending in '.csv'), the results will be written to this file after each function evaluation. This can noticeably slow down solution iterations for quick objective functions. For greedy functions, it can be beneficial to do this in case the script is interrupted. initial_guess : list of floats or ndarray Initial guess used in the solution process. Leave as None to start with a random initial guess. sigma_coeff : float Coefficient in (0, 0.5] to be multiplied by the bound widths for each dimension; the corresponding number is used for the standard deviation in the neighbor generation process. neighbor_dim_changes : int Number of dimensions to mutate during the generation of a new neighbor position. Must be in [1, number of dimensions]. If set to -1, all dimensions will be mutated each iteration. start_temperature : float Initial temperature to start iterations with. alpha : float Temperature decay coefficient in [0.6, 1). The current temperature is multiplied by this at the end of each iteration. Attributes Attribute Description best_position : dict Dictionary containing the most optimal position found during the solution iterations, with variable names as keys and corresponding position values as values. best_value : float Most optimal function value found during the solution iterations. completed_iter : int Number of iterations completed during the solution process. results : pd.DataFrame DataFrame of results throughout the iterations. For each iteration, the function value and position for each member of the population are provided. Methods .optimize ( find_minimum, max_iter=None, max_function_evals=None, max_unchanged_iter=None, sol_threshold=None ) Executes the algorithm solution with the current parameters. Results will be stored to the class attributes. Either max_iter or max_function_evals must be specified in order to prevent an endless optimization loop. In the case of local search algorithms such as this, max_iter or max_function_evals are handled the same way. If any of the criteria are met during optimization, the process is terminated. Argument Description find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. max_iter : int Maximum number of iterations. The algorithm will terminate after completing this many iterations. None indicates that the algorithm will not consider this. max_function_evals : int Maximum number of function evaluations. The algorithm will terminate after completing this many function evaluations. This is a preferable metric for greedy algorithms. None indicates that the algorithm will not consider this. max_unchanged_iter : int If the solution does not improve after this many iterations, the optimization terminates. None indicates that the algorithm will not consider this. sol_threshold : float If a solution is found better than this threshold, the iterations stop. None indicates that the algorithm will not consider this. Example from optiseek.variables import var_float from optiseek.metaheuristics import simulated_annealing from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = simulated_annealing(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=200, sol_threshold=0.05) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.04947 best_position = {'x1': 0.9795801089700062, 'x2': 2.9176223437535667} n_iter = 179 References Simulated Annealing on Wikipedia","title":"Simulated Annealing"},{"location":"simulated_annealing/#simulated-annealing","text":"This class represents the simulated annealing algorithm developed by Kirkpatrick et al. This is a local search method that takes inspiration from the annealing process in metals. Unlike deterministic gradient-based search methods, this algorithm has the ability to avoid being trapped in local optima. This is accomplished because there is a probability that a worse solution could be accepted during each iteration. As the iterations progress (i.e. temperature decreases), this probability diminishes and the algorithm is able to settle into what is hopefully a global optimum. class optiseek.metaheuristics. simulated_annealing ( input_function=None, var_list=None, results_filename=None, initial_guess=None, sigma_coeff=0.2, neighbor_dim_changes=-1, start_temperature=10, alpha=0.90 )","title":"Simulated Annealing"},{"location":"simulated_annealing/#parameters","text":"All parameters are also class attributes and may be modified after instantiation. Parameter Description input_function : function Function that the algorithm will use to search for an optimum. *args will be passed to the function within the solver. var_list : list of variables List of variables (see variable types) to define the search space. These correspond to the arguments of the objective function and must be in the exact same order. results_filename : string If a file name is passed (ending in '.csv'), the results will be written to this file after each function evaluation. This can noticeably slow down solution iterations for quick objective functions. For greedy functions, it can be beneficial to do this in case the script is interrupted. initial_guess : list of floats or ndarray Initial guess used in the solution process. Leave as None to start with a random initial guess. sigma_coeff : float Coefficient in (0, 0.5] to be multiplied by the bound widths for each dimension; the corresponding number is used for the standard deviation in the neighbor generation process. neighbor_dim_changes : int Number of dimensions to mutate during the generation of a new neighbor position. Must be in [1, number of dimensions]. If set to -1, all dimensions will be mutated each iteration. start_temperature : float Initial temperature to start iterations with. alpha : float Temperature decay coefficient in [0.6, 1). The current temperature is multiplied by this at the end of each iteration.","title":"Parameters"},{"location":"simulated_annealing/#attributes","text":"Attribute Description best_position : dict Dictionary containing the most optimal position found during the solution iterations, with variable names as keys and corresponding position values as values. best_value : float Most optimal function value found during the solution iterations. completed_iter : int Number of iterations completed during the solution process. results : pd.DataFrame DataFrame of results throughout the iterations. For each iteration, the function value and position for each member of the population are provided.","title":"Attributes"},{"location":"simulated_annealing/#methods","text":".optimize ( find_minimum, max_iter=None, max_function_evals=None, max_unchanged_iter=None, sol_threshold=None ) Executes the algorithm solution with the current parameters. Results will be stored to the class attributes. Either max_iter or max_function_evals must be specified in order to prevent an endless optimization loop. In the case of local search algorithms such as this, max_iter or max_function_evals are handled the same way. If any of the criteria are met during optimization, the process is terminated. Argument Description find_minimum : bool Indicates whether the optimimum of interest is a minimum or maximum. If true, looks for minimum. If false, looks for maximum. max_iter : int Maximum number of iterations. The algorithm will terminate after completing this many iterations. None indicates that the algorithm will not consider this. max_function_evals : int Maximum number of function evaluations. The algorithm will terminate after completing this many function evaluations. This is a preferable metric for greedy algorithms. None indicates that the algorithm will not consider this. max_unchanged_iter : int If the solution does not improve after this many iterations, the optimization terminates. None indicates that the algorithm will not consider this. sol_threshold : float If a solution is found better than this threshold, the iterations stop. None indicates that the algorithm will not consider this.","title":"Methods"},{"location":"simulated_annealing/#example","text":"from optiseek.variables import var_float from optiseek.metaheuristics import simulated_annealing from optiseek.testfunctions import booth # define a list of variables and their domains for the objective function var_list = [ var_float('x1', [-10, 10]), var_float('x2', [-10, 10]) ] # create an instance of the algorithm to optimize the booth test function and set its parameters alg = simulated_annealing(booth, var_list) # define stopping criteria and optimize alg.optimize(find_minimum=True, max_iter=200, sol_threshold=0.05) # show the results! print(f'best_value = {alg.best_value:.5f}') print(f'best_position = {alg.best_position}') print(f'n_iter = {alg.completed_iter}') best_value = 0.04947 best_position = {'x1': 0.9795801089700062, 'x2': 2.9176223437535667} n_iter = 179","title":"Example"},{"location":"simulated_annealing/#references","text":"Simulated Annealing on Wikipedia","title":"References"},{"location":"variables/","text":"Variable Types Algorithms in optiseek can accept several variable types in addition to just continuous values. Internally, the optimizers treat all variables as continuous numerical dimensions in the search space; however, they are converted back to the appropriate user-specified format when passed to the objective function. Currently, supported variable types are continuous (float), integer, categorical/ordinal, and boolean. Each variable type has its own class. When defining variables and search space bounds for an algorithm, the user passes a list of variable classes into the var_list argument of the algorithm class. Variable Type Class Instantiation Floats/Continuous optiseek.variables. var_float ( var_name, bounds, log_scale=False ) Integers optiseek.variables. var_int ( var_name, bounds, log_scale=False ) Categorical optiseek.variables. var_categorical ( var_name, choices ) Boolean (True/False) optiseek.variables. var_bool ( var_name ) Parameters Parameter Description var_name : string Name of the variable. This will be used to track output and label the stored results if applicable. bounds : list of floats/int A list containing a lower and upper bound for the search space of the variable in the format [lower, upper] . The values can be integers/floats for var_float and must be integers for var_int . choices : list Contains a list of choices to be passed as an argument for the objective function. The list items may be any type that the objective function can accept. log_scale : boolean A flag to toggle on logarithmic scaling for a specified variable. For example, for a continuous variable with search bounds [1, 100], the midpoint without log scaling is 50.5. If log_scale was set to True , the distance in the search space from 1 to 10 would be equivalent to that from 10 to 100. In order to use log_scale , the search space for that variable must be positive. Example from optiseek.variables import * # defining a variable list to be passed to an algorithm var_list = [ var_float('x_float', [-10.5, 10.5]), var_int('x_int', [-2, 5]), var_categorical('x_cat', ['small', 'medium', 'large']), var_bool('x_bool') ]","title":"Variable Types"},{"location":"variables/#variable-types","text":"Algorithms in optiseek can accept several variable types in addition to just continuous values. Internally, the optimizers treat all variables as continuous numerical dimensions in the search space; however, they are converted back to the appropriate user-specified format when passed to the objective function. Currently, supported variable types are continuous (float), integer, categorical/ordinal, and boolean. Each variable type has its own class. When defining variables and search space bounds for an algorithm, the user passes a list of variable classes into the var_list argument of the algorithm class. Variable Type Class Instantiation Floats/Continuous optiseek.variables. var_float ( var_name, bounds, log_scale=False ) Integers optiseek.variables. var_int ( var_name, bounds, log_scale=False ) Categorical optiseek.variables. var_categorical ( var_name, choices ) Boolean (True/False) optiseek.variables. var_bool ( var_name )","title":"Variable Types"},{"location":"variables/#parameters","text":"Parameter Description var_name : string Name of the variable. This will be used to track output and label the stored results if applicable. bounds : list of floats/int A list containing a lower and upper bound for the search space of the variable in the format [lower, upper] . The values can be integers/floats for var_float and must be integers for var_int . choices : list Contains a list of choices to be passed as an argument for the objective function. The list items may be any type that the objective function can accept. log_scale : boolean A flag to toggle on logarithmic scaling for a specified variable. For example, for a continuous variable with search bounds [1, 100], the midpoint without log scaling is 50.5. If log_scale was set to True , the distance in the search space from 1 to 10 would be equivalent to that from 10 to 100. In order to use log_scale , the search space for that variable must be positive.","title":"Parameters"},{"location":"variables/#example","text":"from optiseek.variables import * # defining a variable list to be passed to an algorithm var_list = [ var_float('x_float', [-10.5, 10.5]), var_int('x_int', [-2, 5]), var_categorical('x_cat', ['small', 'medium', 'large']), var_bool('x_bool') ]","title":"Example"},{"location":"wheelers_ridge/","text":"Wheeler's Ridge This is a 2D function with a global minimum in a deep valley. It is mostly smooth other than two ridges along each of the principal axes. These cause some algorithms to converge into local minima or diverge. In this form, the minimum is at [1, 1.5] with a value of -1. Form of the function is as follows: function optiseek.testfunctions. wheelers_ridge ( x1, x2 ) Parameters Parameter Description x1 : float Input value for the first dimension. x2 : float Input value for the second dimension. Example from optiseek.testfunctions import wheelers_ridge y = wheelers_ridge(1, 1.5) -1 References List of Test Functions on Wikipedia","title":"Wheeler's Ridge"},{"location":"wheelers_ridge/#wheelers-ridge","text":"This is a 2D function with a global minimum in a deep valley. It is mostly smooth other than two ridges along each of the principal axes. These cause some algorithms to converge into local minima or diverge. In this form, the minimum is at [1, 1.5] with a value of -1. Form of the function is as follows: function optiseek.testfunctions. wheelers_ridge ( x1, x2 )","title":"Wheeler's  Ridge"},{"location":"wheelers_ridge/#parameters","text":"Parameter Description x1 : float Input value for the first dimension. x2 : float Input value for the second dimension.","title":"Parameters"},{"location":"wheelers_ridge/#example","text":"from optiseek.testfunctions import wheelers_ridge y = wheelers_ridge(1, 1.5) -1","title":"Example"},{"location":"wheelers_ridge/#references","text":"List of Test Functions on Wikipedia","title":"References"}]}